# 线性代数

吉尔伯特·斯特朗的线性代数课程

## 方程组

假设有两个未知数的方程组

$$
\begin{cases}
    2x-y=0 \\
    -x+2y=3
\end{cases}
$$

方程式的系数矩阵为：

$$
\begin{bmatrix}
   2 & -1 \\
   -1 & 2 
\end{bmatrix}
$$

方程式的矩阵形式为：

$$
\begin{bmatrix}
    2 & -1 \\
    -1 & 2 
\end{bmatrix}
\begin{bmatrix}
    x\\
    y
\end{bmatrix} = 
\begin{bmatrix}
    0 \\
    3
\end{bmatrix}
$$

可以写为 A·X=b

### 行图像

上述方程组的行图像为：一次取一行在xy平面上作出满足该方程的图像，图像上的所有点均为该方程的解。

两条直线的交点同时满足两个方程，是方程组的解。

### 列图像

看矩阵的列，将方程组写为：

$$
x \begin{bmatrix} 2 \\ -1 \end{bmatrix} + y \begin{bmatrix} -1 \\ 2 \end{bmatrix} = \begin{bmatrix} 0 \\ 3 \end{bmatrix}
$$

x、y后的参数为矩阵的各列，方程的右侧为参数b。

该方程组的意义是：**列向量的线性组合**。寻找将[2 -1]T和[-1 2]T线性组合起来能够得到[0 3]T的参数x和y；即寻找这两个向量的线性组合。

其几何图像为，xy坐标系下的两个向量，[2,-1]和[-1,2]，在图上将其线性组合得到[0,3]（可以理解为向量的平行四边形法则）。

这两个向量的所有线性组合是什么？

任意的x y可以使这两个向量得到所有可能的右侧向量b，包含整个平面上的点（前提是这两个向量线性无关？）

### 3x3例子

三个方程，三个维度xyz

$$
\begin{cases}
    2x-y=0  \\
    -x+2y-z=-1  \\
    -3y+4z=4
\end{cases}
$$

矩阵形式：

$$
A = \begin{bmatrix}\ 2 & -1 & 0 \\ -1 & 2 & -1 \\ 0 & -3 &4 \end{bmatrix}
$$

$$
X = \begin{bmatrix} x \\ y \\ z \end{bmatrix}
$$

$$
b = \begin{bmatrix} 0 \\ -1 \\ 4 \end{bmatrix}
$$

#### 行图像

从该方程组中一次取一个方程，可知该方程组的三个行图像分别为xyz三维空间中的三个平面。这三个平面相交得到的结果即为方程组的解。

有可能是，两个平面相交得到一条直线，直线与第三个平面相交得到一个点，也有可能其中两个平面平行，则该方程组无解。

#### 列图像

教授说他更倾向于列图像

$$
X \begin{bmatrix} 2 \\ -1 \\ 0 \end{bmatrix} +
Y \begin{bmatrix} -1 \\ 2 \\ -3 \end{bmatrix} +
Z \begin{bmatrix} 0 \\ -1 \\ 4 \end{bmatrix} =
\begin{bmatrix} 0 \\ -1 \\ 4 \end{bmatrix}
$$

此时可以将方程组看作求[2,-1,0]T [-1,2,-3]T 和 [0,-1,4]T 三个向量的线性组合使其得到 [0,-1,4]T

三个三维向量的线性组合，也可以通过画图看出来。（此时可以一眼看出来一个解为 (0 0 1)）因为右侧向量为左侧向量中的一个，所以只需要留下该列向量，其他的不需要。（0，0，1）就是三个平面的交点。

要系统地求解线性方程组，可以使用消元法，可以求所有情况下的xyz。

接下来保持左侧不变，考虑不同的右侧向量，例如只是简单的将第一列和第二列加在一起：

$$
X \begin{bmatrix} 2 \\ -1 \\ 0 \end{bmatrix} +
Y \begin{bmatrix} -1 \\ 2 \\ -3 \end{bmatrix} +
Z \begin{bmatrix} 0 \\ -1 \\ 4 \end{bmatrix} =
\begin{bmatrix} 1 \\ 1 \\ -3 \end{bmatrix}
$$

此时的解为（1，1，0）

考虑所有的b，是否所有的b都能使方程组有解？等价于代数问题："对于所有b，是否能求解Ax=b？"

如果换到线性代数的角度讲，这个问题也可以变成：列的线性组合是否覆盖整个三维空间？任意的b其实就是三维空间的意思。

对于上面这个例子的A，该问题的答案是可以的。因为该A是**非奇异矩阵**，是**可逆矩阵**。

但是对于另一些矩阵来说，答案是不可以。例如当三个向量处在同一个平面上时，它们的线性组合肯定也在该平面上，此时当b在该平面上时方程组有解，当b不在该平面上时无解，这种情况下称为**奇异矩阵**，矩阵不可逆。

### 九维情况

假设向量有9个分量，这种情况很难具象化。假设有9个方程和9个未知数，此时有9列，每一列都是九尾空间，此时考虑其线性组合。对于该问题，同样问：对于任意的b是否均有Ax=b？

问题的答案也一样，取决于系数矩阵A，A可逆则有，A不可逆则无。

如果选择一些**相互不独立的**列向量，例如第九列其实跟第八列一样，此时有一列毫无贡献（没有提供新的信息？）。此时就会有一些b无法求解，只有九维空间的八维平面上的b可以求解。

### 方程组的矩阵形式

矩阵A诚意某向量x等于右侧向量b

$$
    Ax = b
$$

**前提：A的列数等于b的行数，矩阵间的乘法也是，左乘矩阵的列数等于右乘矩阵的行数**

该方程式为一个矩阵乘以向量，举例：

$$
\begin{bmatrix}
    2 & 5 \\
    1 & 3
\end{bmatrix}
\begin{bmatrix}
    1 \\
    2
\end{bmatrix}
$$

#### 以列的形式计算

一次取一列，该例子可以看成：取一个第一列，加两个第二列

$$
1
\begin{bmatrix}
    2 \\
    1
\end{bmatrix}
+
2
\begin{bmatrix}
    5 \\
    3
\end{bmatrix}
=
\begin{bmatrix}
    12 \\
    7
\end{bmatrix}
$$

#### 以行的形式计算

用左侧矩阵的第一行，点乘该列向量，得到结果的第一行，第二行点乘该列向量得到结果的第二行。

$$
1
\begin{bmatrix}
    2 \\
    1
\end{bmatrix}
+
2
\begin{bmatrix}
    5 \\
    3
\end{bmatrix}
=
\begin{bmatrix}
    \begin{bmatrix}
        2 & 5
    \end{bmatrix}
    \begin{bmatrix}
        1 \\
        2
    \end{bmatrix} \\
    \begin{bmatrix}
        1 & 3
    \end{bmatrix}
    \begin{bmatrix}
        1 \\
        2
    \end{bmatrix}
\end{bmatrix}
=
\begin{bmatrix}
    2*1+5*2 \\
    1*1 + 3*2
\end{bmatrix}
=
\begin{bmatrix}
    12 \\
    7
\end{bmatrix}
$$

在数据较少，矩阵维度比较低，例如低于三维时，可以用列的方式计算，但是数据量大维度高时用第二种算法。

但是这样思考也是一种不错的思想：<br />
**Ax可以看作A各列的线性组合**

## 消元法

一种系统性求解方程组的方法，可以求解任意元的方程组，以及什么情况下该方程组无解。所有计算机程序都是使用的这种方法。

如果消元法奏效，则能够求出方程组的解。输入矩阵A是一个好矩阵（可逆），即可得到解。如果考虑消元法不奏效，可以知道矩阵何时是好矩阵，何时有问题。

为了求出解，还有一个回代过程。

消元的概念很自然，但是在线性代数中需要将其描述为**矩阵变换**。

考虑方程组：

$$
\begin{cases}
x+2y+z=2 \\
3x+8y+z=12 \\
4y+z=2
\end{cases}
$$

Ax=b的形式：

$$
\begin{bmatrix}
    1 & 2 & 1 \\
    3 & 8 & 1 \\
    0 & 4 & 1
\end{bmatrix}
\begin{bmatrix}
    x \\
    y \\
    z
\end{bmatrix}
=
\begin{bmatrix}
    2 \\
    12 \\
    2
\end{bmatrix}
$$

在进行消元法时，用矩阵描述。

### 消元

消元步骤：第一个方程成立，用该方程乘以某个数，然后从方程二中将其减去，目的是消去方程二中的x。

首先这个1是开始消元的关键，它称为**主元**，第一个主元，消元乘数为3，可以从方程二中消去x。

**主元不可为0**

假设方程1中没有x，则此时矩阵A的(1,1)位置为0，通过行交换可以使其不为0。**当主元为0时，可以通过行交换在下面的方程中找到合适的主元**

$$
\begin{bmatrix}
    [1] & 2 & 1 \\
    3 & 8 & 1 \\
    0 & 4 & 1
\end{bmatrix}
->
\begin{bmatrix}
    [1] & 2 & 1 \\
    3-1*3 & 8-2*3 & 1-1*3 \\
    0 & 4 & 1
\end{bmatrix}
->
\begin{bmatrix}
    [1] & 2 & 1 \\
    0 & 2 & -2 \\
    0 & 4 & 1
\end{bmatrix}
$$

第一步完成，计算中可以将b附在后面一同计算（matlab的计算过程是先算左侧，再回头算右侧）。该步骤中除去的是(2,1)位置，第二行的第一列。下一步需要将该列(第一列)下方的所有元素清零（该例中已经为0）。


接下来看第二个主元，在(2,2)，希望用其消去(3,2)位置，取消元乘数为2。

$$
\begin{bmatrix}
    1 & 2 & 1 \\
    0 & [2] & -2 \\
    0 & 4 & 1 
\end{bmatrix}
->
\begin{bmatrix}
    1 & 2 & 1 \\
    0 & [2] & -2 \\
    0-0*2 & 4-2*2 & 1-(-2)*2 
\end{bmatrix}
->
\begin{bmatrix}
    1 & 2 & 1 \\
    0 & [2] & -2 \\
    0 & 0 & 5 
\end{bmatrix}
$$

最终得到的矩阵如下，称其为U(上三角矩阵)，其三个主元已经标出

$$
U = 
\begin{bmatrix}
    [1] & 2 & 1 \\
    0 & [2] & -2 \\
    0 & 0 & [5] 
\end{bmatrix}
$$

**失效的情况**：无法得到三个主元，矩阵不可逆。

### 回代

代入右侧向量b，与参数矩阵A组成**增广矩阵**，做与消元同样的运算。

$$
\begin{bmatrix}
    1 & 2 & 1 & | & 2 \\
    3 & 8 & 1 & | & 12 \\
    0 & 4 & 1 & | & 2
\end{bmatrix}
->
\begin{bmatrix}
    1 & 2 & 1 & | & 2 \\
    0 & 2 & -2 & | & 6 \\
    0 & 4 & 1 & | & 2
\end{bmatrix}
->
\begin{bmatrix}
    1 & 2 & 1 & | & 2 \\
    0 & 2 & -2 & | & 6 \\
    0 & 0 & 5 & | & -10
\end{bmatrix}
$$

最终的方程为：

$$
\begin{cases}
    x+2y+z=2 \\
    2y-2z=6 \\
    5z=-10
\end{cases}
$$

回代时，先解z，向上回代逐步解出其余量。

$$
\begin{cases}
    x=2 \\
    y=1 \\
    z=-2
\end{cases}
$$

### 消元矩阵

原始矩阵A:

$$
A = 
\begin{bmatrix}
    1 & 2 & 1 \\
    3 & 8 & 1 \\
    0 & 4 & 1
\end{bmatrix}
$$

之前讲过，矩阵乘以向量是取其列的线性组合。

$$
\begin{bmatrix}
    col1[1] & col2[1] & col3[1] \\
    col1[2] & col2[2] & col3[2] \\
    col1[3] & col2[3] & col3[3]
\end{bmatrix}
\begin{bmatrix}
    3 \\
    4 \\
    5
\end{bmatrix}
=
3*col1 + 4*col2 + 5*col3
=
\begin{bmatrix}
    3*col1[1] + 4*col2[1] + 5*col3[1] \\
    3*col1[2] + 4*col2[2] + 5*col3[2] \\
    3*col1[3] + 4*col2[3] + 5*col3[3]
\end{bmatrix}
$$

考虑行的形式

$$
\begin{bmatrix}
    1 & 2 & 7
\end{bmatrix}
\begin{bmatrix}
    row1[1] & row1[2] & row1[3] \\
    row2[1] & row2[2] & row2[3] \\
    row3[1] & row3[2] & row3[3]
\end{bmatrix}
=
1*row1 + 2*row2 + 7*row3
$$
$$
=
\begin{bmatrix}
    1*row1[1] + 2*row2[1] + 7*row3[1] & 1*row1[2] + 2*row2[2] + 7*row3[2] & 1*row1[3] + 2*row2[3] + 7*row3[3]
\end{bmatrix}
$$

线性代数的核心概念：分别用行和列进行矩阵操作，矩阵乘以一个列结果为一列，是对列进行组合，一行乘以一个矩阵结果为一行，是对行进行组合。

回到消元，在之前的消元步骤中，消元是通过行变换进行的。所以若要用矩阵变换表示消元过程，该操作应该为：以一个行向量左乘该矩阵。具体如下：

$$
\begin{bmatrix}
    1 & 0 & 0 \\
    -3 & 1 & 0 \\
    0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
    1 & 2 & 1 \\
    3 & 8 & 1 \\
    0 & 4 & 1
\end{bmatrix}
=
\begin{bmatrix}
    1 & 2 & 1 \\
    0 & 2 & -2 \\
    0 & 4 & 1
\end{bmatrix}
$$

可以将上述左乘的矩阵称为**初等矩阵**，记作E1：

$$
E21 = 
\begin{bmatrix}
    1 & 0 & 0 \\
    -3 & 1 & 0 \\
    0 & 0 & 1
\end{bmatrix}
$$

:::tip 单位阵

综上，可以发现，下面这个矩阵(单位阵)可以使原来的矩阵不发生任何变化

$$
\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
\end{bmatrix}
$$

:::

接下来，第二步消元操作为：

$$
\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & -2 & 1
\end{bmatrix}
\begin{bmatrix}
    1 & 2 & 1 \\
    0 & 2 & -2 \\
    0 & 4 & 1
\end{bmatrix}
=
\begin{bmatrix}
    1 & 2 & 1 \\
    0 & 2 & -2 \\
    0 & 0 & 5
\end{bmatrix}
$$

将该步骤中的左乘矩阵记作E2：
$$
E32 = 
\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & -2 & 1
\end{bmatrix}
$$


所以，上述两部分别做左乘了两个矩阵。根据矩阵乘法的结合律，可以将这两个矩阵合成为同一个矩阵:

:::warning
矩阵没有交换律！不能改变乘法中矩阵的位置，AB≠BA
:::

$$
    E32 (E21 A) = U
$$

$$
    (E32 E21) A = U
$$

$$
    E = E32 E21 = 
    \begin{bmatrix}
        1 & 0 & 0 \\
        -3 & 1 & 0 \\
        0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & -2 & 1
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 & 0 \\
        -3 & 1 & 0 \\
        0 & -2 & 1
    \end{bmatrix}
$$

:::tip 置换矩阵

交换两行的矩阵，本质上来讲，就是单位阵行变换的所有组合。将单位阵对应行交换，得到的就是将这两行交换的置换矩阵。

$$
\begin{bmatrix}
    0 & 1 & 0 \\
    1 & 0 & 0 \\
    0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
    0 & 0 & 1 \\
    0 & 1 & 0 \\
    1 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 0 & 1 \\
    0 & 1 & 0
\end{bmatrix}
$$

若要交换列，矩阵的形式一样，但是需要右乘。将单位阵的两列交换得到的矩阵就是将这两列交换的置换矩阵。
:::

但是还有更好的办法，不是关心A怎么变成U，而是U怎么变回A。接下来进行逆变换。

:::tip 矩阵的逆
矩阵A，矩阵A的逆为A^{-1}

A^{-1}A = I

:::

$$
    EA=U
$$
$$
    E^{-1}EA=E^{-1}U
$$
$$
    A=E^{-1}U
$$

## 矩阵乘法

假设有矩阵A，B，C，AB=C。回顾单个元素的算法，C中第i行第j列处的元素$C~ij~$，为A的第i行与B的第j列的点积。

:::warning
矩阵相乘的前提：左乘矩阵的行数等于右乘矩阵的列数。
$A~mn~$，$B~np~$
:::

假设有k个元素。

$$
C_{ij} = \sum_{k=1}^n A_{ik}B_{kj}
$$

常规方法：用列乘以行，得到一个数字。

列方法：看整列的情况，A乘以B的第一列得到aoC的第一列，B可以考虑成p个单独的列。C中的各列是A中各列的线性组合。

行方法：看整行的情况，A的某一行乘以B中的每一行，得到C中的一行。C中的各行是B中各行的的线性组合。

列乘以行：A的一列乘以B的一行，得到的是一个完整的矩阵。A的一列为mx1，B的一行为1xp，结果为mxp。例如：

$$
\begin{bmatrix}
 2 \\ 3 \\ 4
\end{bmatrix}
\begin{bmatrix}
    1 & 6
\end{bmatrix}
=
\begin{bmatrix}
    2 & 12 \\
    3 & 18 \\
    4 & 24
\end{bmatrix}
$$

结果的各列都是$\begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix}$的倍数，各行都是$\begin{bmatrix} 1 & 6 \end{bmatrix}$的倍数。结果的所有行都依赖于$\begin{bmatrix} 1 & 6 \end{bmatrix}$，所有列都依赖于$\begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix}$。所有的行向量都在同一个方向，所有的列向量也在同一个方向。**该矩阵的行空间是一条直线，列空间也是一条直线**

AB是A的各列乘以B的各行所得矩阵之和。

还可以将矩阵切成许多块，对块进行乘法。例如可以将A分为4块，B也分为4块，只要各块相匹配即可

$$
A=
\begin{bmatrix}
    A_1 & A_2 \\
    A_3 & A_4
\end{bmatrix}
$$

$$
B=
\begin{bmatrix}
    B_1 & B_2 \\
    B_3 & B_4
\end{bmatrix}
$$

$$
AB=
\begin{bmatrix}
    A_1 & A_2 \\
    A_3 & A_4
\end{bmatrix}
\begin{bmatrix}
    B_1 & B_2 \\
    B_3 & B_4
\end{bmatrix}
=
\begin{bmatrix}
    A_1B_1+A_2B_3 & A_1B_2+A_2B_4 \\
    A_3B_1+A_4B_2 & A_3B_2+A_4B_4
\end{bmatrix}
$$

## 矩阵的逆

Inverse

先考虑方阵A，A可能有也可能没有逆。如果A可逆或者非奇异，那么就存在某个矩阵，称为A的逆$A^{-1}$

$$
    A^{-1}A = I
$$

$$
    AA^{-1} = I
$$

对于方阵，其左逆矩阵等于右逆矩阵，这一点不好证明，但是是正确的。非方阵的左逆和右逆不一样。

对于奇异阵，没有逆。举一个2x2的例子：

$$
A=
\begin{bmatrix}
    1 & 3 \\
    2 & 6
\end{bmatrix}
$$

该矩阵为什么没有逆矩阵？接下来有若干解释：

1. 如果取行列式，该矩阵的行列式为0。

2. 假设A乘以某个矩阵得到单位阵，考虑其列，结果中的各列都来自A中的列，这样不可能得到单位阵，A中的两列共线，不可能得到$\begin{bmatrix} 1 \\ 0 \end{bmatrix}$。

3. 如果存在非零向量X使得AX=0，这样的矩阵没有逆。这里的X是$\begin{bmatrix} 3 \\ -1 \end{bmatrix}$。如果此时A存在逆矩阵的话，就不会有AX=0存在：

$$
    AX = 0
$$

$$
    A^{-1}AX = A^{-1}0
$$

$$
    IX=0
$$

$$
    X=0
$$

如果其中一列对线性组合毫无贡献，矩阵不可能有逆。

结论是：不可逆矩阵、奇异矩阵其列能通过线性组合得到0

什么样的矩阵有逆？例如：
$$
\begin{bmatrix}
    1 & 3 \\
    2 & ?
\end{bmatrix}
$$

？处可以为：7，8，等等但是就是不能为6。偏爱行列式的人会算出该矩阵的行列式不为0，偏爱列的人会发现这两列不共线，等等。

如何求出矩阵的逆？

$$
\begin{bmatrix}
    1 & 3 \\
    2 & 7
\end{bmatrix}
\begin{bmatrix}
    ? & ? \\
    ? & ?
\end{bmatrix}
=
\begin{bmatrix}
    1 & 0 \\
    0 & 1
\end{bmatrix}
$$

取第一列，令其为a，b，此时满足方程A乘以该列可以得到$\begin{bmatrix} 1 & 0 
\end{bmatrix}$<br />
取第二列，令其为c，d，此时满足方程A乘以该列可以得到$\begin{bmatrix} 0 & 1 
\end{bmatrix}$

$$
\begin{bmatrix}
    1 & 3 \\
    2 & 7
\end{bmatrix}
\begin{bmatrix}
    a & c \\
    b & d
\end{bmatrix}
=
\begin{bmatrix}
    1 & 0 \\
    0 & 1
\end{bmatrix}
$$

$$
\begin{cases}
    \begin{bmatrix}
        1 & 3 \\
        2 & 7
    \end{bmatrix}
    \begin{bmatrix}
        a \\
        b
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 \\
        0
    \end{bmatrix} \\
    \begin{bmatrix}
        1 & 3 \\
        2 & 7
    \end{bmatrix}
    \begin{bmatrix}
        c \\
        d
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 \\
        1
    \end{bmatrix}
\end{cases}
$$

这就是高斯Gauss的方法。求逆其实与求方程组是一样的，但是在矩阵维度较高时，这种方法计算量就非常大了。

此时引入高斯-若尔当 Gauss-Jordan思想，可以同时处理两个方程组。

在该矩阵右侧加上一个单位阵$\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$，称为一个增广矩阵。再在此基础上进行消元，将左侧变为单位阵，右侧即为逆矩阵。

$$
\begin{bmatrix}
    1 & 3 & | & 1 & 0 \\
    2 & 7 & | & 0 & 1
\end{bmatrix}
$$

$$
\begin{bmatrix}
    1 & 3 & | & 1 & 0 \\
    0 & 1 & | & -2 & 1
\end{bmatrix}
$$

$$
\begin{bmatrix}
    1 & 0 & | & 7 & -3 \\
    0 & 1 & | & -2 & 1
\end{bmatrix}
$$

为什么这里能够得到A的逆？只进行了行变换，相当于左乘之前得出的行变换矩阵E。

$$
    E[AI] = [IE]
$$
$$
    EA = I
$$
$$
    E = A_{-1}
$$

## LU分解

本节最后要得出的公式是
$$
A = LU
$$

假设$A$可逆，$B$也可逆，什么矩阵能给出$AB$的逆，或者说$AB$的逆是什么？是用$B^{-1}A^{-1}$

假设$A$可逆，该矩阵的转置的逆是什么？
$$
AA^{-1} = I
$$
两边同时转置
$$
(AA^{-1})^T = I^T
$$
$$
(A^{-1})^TA^T = I
$$
所以转置的逆是**逆的转置**

以上是本节要用到的基础公式。消元的目的是为了正确认识矩阵的概念，$A=LU$是最基础的矩阵分解。

假设有可逆矩阵$A$，不需要进行行互换，可以进行消元，主元的位置也很好，可以从$A$得到$U$，其中的关联是什么，$A$和$U$是什么关系。

考虑2x2的情形。

$$
A = 
\begin{bmatrix}
    2 & 1 \\
    8 & 7
\end{bmatrix}
$$
用初等矩阵进行行变换
$$
    E_{21}A = U
$$
$$
    \begin{bmatrix}
        1 & 0 \\
        -4 & 1
    \end{bmatrix}
    \begin{bmatrix}
        2 & 1 \\
        8 & 7
    \end{bmatrix}
    =
    \begin{bmatrix}
        2 & 1 \\
        0 & 3
    \end{bmatrix}
$$

本节要得出的公式是$A=LU$，A在一侧，其余矩阵在另一侧

$$
    E_{21}^{-1}E_{21}A = E_{21}^{-1}U
$$

$$
    A = E_{21}^{-1}U
$$
$L$其实就是$E$的逆
$$
    A = LU
$$

**消元矩阵的逆很好求，只要改变一个符号就行**

$$
    \begin{bmatrix}
        1 & 0 \\
        4 & 1
    \end{bmatrix}
    \begin{bmatrix}
        1 & 0 \\
        -4 & 1
    \end{bmatrix}
    \begin{bmatrix}
        2 & 1 \\
        8 & 7
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 \\
        4 & 1
    \end{bmatrix}
    \begin{bmatrix}
        2 & 1 \\
        0 & 3
    \end{bmatrix}
$$

$$
    \begin{bmatrix}
        2 & 1 \\
        8 & 7
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 \\
        4 & 1
    \end{bmatrix}
    \begin{bmatrix}
        2 & 1 \\
        0 & 3
    \end{bmatrix}
$$

此时已经初具雏形了，$L$表示什么？$U$表示上三角upper，$L$表示下三角lower。式子可以进一步写为：

$$
    \begin{bmatrix}
        2 & 1 \\
        8 & 7
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 \\
        4 & 1
    \end{bmatrix}
    \begin{bmatrix}
        2 & 0 \\
        0 & 3
    \end{bmatrix}
    \begin{bmatrix}
        1 & \frac{1}{2} \\
        0 & 1
    \end{bmatrix}
$$

该形式称为

$$
A = LDU
$$

$L$：下三角矩阵 $D$：对角阵 $U$：上三角矩阵

但是对于3x3矩阵，情况就很不同

假设$A$为一3x3矩阵，第一步使用$E_{21}$在21位置得到0(假设没有进行行变换)，以此类推...

$$
    E_{32}E_{31}E_{21}A = U
$$

此时的$L$也不一样

$$
    A = E_{21}^{-1}E_{31}^{-1}E_{32}^{-1}U
$$

$$
    L = (E_{32}E_{31}E_{21})^{-1}
$$

假设：

$$
    E_{21} =
    \begin{bmatrix}
        1 & 0 & 0 \\
        -2 & 1 & 0 \\
        0 & 0 & 1
    \end{bmatrix}
$$

$$
    E_{31} =
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{bmatrix}
$$

$$
    E_{32} = 
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & -5 & 1
    \end{bmatrix}
$$

这个例子比较典型，相当于没有$E_{31}$

$$
    E = E_{32}E_{21}
$$

$$
    E = 
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & -5 & 1
    \end{bmatrix}
    \begin{bmatrix}
        1 & 0 & 0 \\
        -2 & 1 & 0 \\
        0 & 0 & 1
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 & 0 \\
        -2 & 1 & 0 \\
        10 & -5  & 1
    \end{bmatrix}
$$

**这个10是怎么来的？**<br />
因为第二行减去了两倍的第一行得到-2，第三行减去五倍的第二行得到10，相当于第三行加上了10倍的第一行

从反方向开始计算逆：

$$
    L = E^{-1}
$$

$$
    L = E_{21}^{-1}E_{32}^{-1}
$$

$$
    L =
    \begin{bmatrix}
        1 & 0 & 0 \\
        2 & 1 & 0 \\
        0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 5 & 1
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 & 0 \\
        2 & 1 & 0 \\
        0 & 5 & 1
    \end{bmatrix}
$$

所以

$$
    L =
    \begin{bmatrix}
        1 & 0 & 0 \\
        2 & 1 & 0 \\
        0 & 5 & 1
    \end{bmatrix}
$$
$$
    E =
    \begin{bmatrix}
        1 & 0 & 0 \\
        -2 & 1 & 0 \\
        10 & -5  & 1
    \end{bmatrix}
$$

$$
    A = LU
$$

如果不存在行互换，消元乘数即消元步骤中要乘以并减去的那个倍数可以直接写入L中。

比如进行消元步骤，只要步骤正确，可以在得到LU的过程中把A抛开。这样考虑消元步骤：当完成A第二行中的消元，得到U的第二行，同时得到了消元乘数，此时可以不管A了，因为A的信息都包含在LU中。

一个nxn矩阵A，消元需要进行多少次操作？(如果一次加法和一次乘法算一次)<br />
$$
    n^2 + (n-1)^2 + ... + 1^2
$$
$$
    \frac{1}{3}n^3
$$

接下来允许行互换操作。当主元位置存在0时，需要进行行互换操作。这就进入了转置与置换。置换矩阵用于进行行互换操作。

由单位矩阵各行交换就能得到行变换矩阵，行变换矩阵两两相乘结果仍在他们中间，各自的逆是其转置。

## 转置 置换 向量空间

### 置换 Permutation

置换矩阵，记作P，是用来完成行互换的矩阵。

在之前的矩阵分解中，$A=LU$，$L$主元位置均为1，消元乘数在下三角位置，上三角位置均为0，$U$下三角位置均为0。

这样的例子中没有进行行互换，因为之前的矩阵都是主元位置没有0的，但是通常情况不一定是这样。而且在matlab中，matlab不会像人一样，matlab不仅不允许主元位置出现零，而且不允许主元位置上出现非常小的数值，因为这样会对数值计算的准确性有影响。matlab就会对一些在人看来没有必要的行进行互换操作。

而在有了行变换后，$A=LU$就变成了$PA=LU$。其中P为行互换矩阵，它将各行互换为正确的顺序，互换后主元位置不会出现0，并且L和U仍保持上面的形式。

对于任何可逆矩阵都有$PA=LU$这种形式。对于大部分矩阵，不需要P，但有一些需要。

置换矩阵是行重新排列了的单位矩阵。

n阶矩阵有n！种置换矩阵

### 转置 Transpose

转置是将矩阵的行列互换，记作T，matlab用'表示。

$$$
    (A^T)_{ij} = A_{ji}
$$

$$
    A =
    \begin{bmatrix}
        1 & 3 \\
        2 & 3 \\
        4 & 1
    \end{bmatrix}
$$

$$
    A^T =
    \begin{bmatrix}
        1 & 2 & 4 \\
        3 & 3 & 1
    \end{bmatrix}
$$

### 对称矩阵

对称矩阵转置之后不变

$$
    A^T = A
$$

所有的矩阵$R$乘以$R^T$都是对称矩阵。

## 向量空间

空间表示有很多向量，但并不是任意向量的组合都能称为空间。空间必须满足一些条件，必须能进行**线性组合**。

例如R^2就是一个向量空间，R^2表示二维实向量，例如(3, 2) (0, 0) (Π, e)等等。首先进行代数运算，例如两两相加，各个分量相加，还能做出图像。它们的图象是，由原点出发，指向坐标处的箭头，(0, 0)自己在原点，且没有箭头指向。此时整个二位平面就是R^2，可以将R^2称为一个平面，但是此时考虑成其为所有向量组成的向量空间。如果将(0, 0)去掉，相当于在xy平面戳破一个洞。对于向量空间，一个向量乘以任何数都必须属于向量空间，加上任何向量都必须属于向量空间。而如果没有原点(0, 0)，则一个向量乘以0，得到的结果不在空间内，一个向量加上与其相反的向量，得到的结果也不在空间内，此时没有(0, 0)的xy平面就不是向量空间了。

**所有向量空间必须包含0向量**

与R^2相同的向量空间还有R^3，R^3是所有三维实向量组成的向量空间。R^n包含所有的n维实向量。

### 向量空间的性质

首先以R^2为例，必须有两两相加仍在R^2中，数乘也仍在R^2中，线性组合也在R^2中。对于R^n也一样。对于这些运算，加减和数乘需要遵循一些法则。这些运算法则并不是什么问题，但是能否在**运算完成后仍处于空间内**？

例如一个非向量空间，只取xy平面的第一象限，其为R^2的$\frac{1}{2}$，所有分量均为正值。其对于加法，两个向量相加后仍然在第一象限内，但是减法就不一定了。所以第一象限不是向量空间，其对于实数的数乘和减法不是封闭的。

**向量空间必须对数乘和加法两种运算封闭，对线性组合封闭**

R^n是一个很重要的向量空间，但是我们更关注R^n内的向量空间。这些向量空间满足既定规则，但无需包含所有向量。

从R^2开始讨论，有哪些空间虽然只是R^2的一部分，但不管是加法还是数乘，结果依然在此空间内？这就是所谓的**子空间**。<br />
1. 首先考虑R^2本身，它是它自己的子空间
2. 穿过原点两端无限延申的的所有直线。与R^1不同，R^1虽然也是一条直线，但是R^1只有一个分量，R^2有两个分量。
3. 原点

而对于R^3，有：
1. R^3本身
2. 过原点的平面
3. 过原点的直线
4. 原点

实际情况中，矩阵如何构造子空间

取
$$
    A = 
    \begin{bmatrix}
        1 & 3 \\
        2 & 3 \\
        4 & 1
    \end{bmatrix}
$$

第一种方法：通过列向量构造

A中的各列均属于R^3，用这些列来构造R^3的子空间。子空间中现在已经有了这两个列向量，这两个向量的和需要在子空间中，$\begin{bmatrix}1 \\ 2 \\ 4\end{bmatrix}$在子空间内，$\begin{bmatrix}3 \\ 3 \\ 1\end{bmatrix}$在子空间中，它们的和$\begin{bmatrix}4 \\ 5 \\ 5\end{bmatrix}$也在子空间中，它们乘以任何数也应该在子空间中，零向量$\begin{bmatrix}0\\0\\0\end{bmatrix}$也在子空间中，所有的线性组合构成一个子空间。这个就是矩阵A的**列空间**，记作C(A)。

通过某些向量可以构成一个向量组成的空间，如果这些向量属于R^3，它们构成的空间也在R^3内。关键是对其进行线性组合后仍然在子空间内。

几何上，这个子空间是(1, 2, 4) (3, 3, 1) (0, 0, 0)三个点组成的平面。R^3还可以作图，但是R^10呢，可能需要求R^10中5个向量的线性组合。结果可能是某种子空间。5个向量，每个向量有10各分量，取其线性组合，不会得到R^5，因为有10个分量，可能是10维空间中的5维平面，若这5个向量共线，也可能是一条自直线。

第二种方法：通过行向量构造。此例中得到的回事一个平面。

## 零空间 列空间

向量空间：一些向量，对一些运算封闭，空间内任两向量相加(加法)，结果任在空间内，或者用空间内任一向量乘以某常数（数乘），结果仍在空间内。**任意线性组合仍在空间内**

子空间：向量空间中的一些空间，属于母空间，但其本身也构成向量空间。

### 列空间

矩阵A的列空间，例如A

$$
    A =
    \begin{bmatrix}
        1 & 1 & 2 \\
        2 & 1 & 3 \\
        3 & 1 & 4 \\
        4 & 1 & 5
    \end{bmatrix}
$$

A的列空间是R^4的子空间，记作C(A)。C(A)中除了含有A中各列外，还有A各列的线性组合。

这个空间具体是什么样的？是整个四维空间，还是其一子空间。取这三个列向量的线性组合，填充不了整个四维空间，所以他是一个较小的四维空间。将其与线性方程组联系起来。

假设Ax=b，对任意b其是否都有解，什么样的b使方程有解：

Ax=b不会对任意b有解，因为Ax=b中有四个方程，但是只有三个未知数。

$$
    Ax = 
    \begin{bmatrix}
        1 & 1 & 2 \\
        2 & 1 & 3 \\
        3 & 1 & 4 \\
        4 & 1 & 5
    \end{bmatrix}
    \begin{bmatrix}
        x_1 \\
        x_2 \\
        x_3
    \end{bmatrix}
    =
    \begin{bmatrix}
        b_1 \\
        b_2 \\
        b_3 \\
        b_4
    \end{bmatrix}
$$

方程不总有解，3个列向量的线性组合无法充满整个四维空间，有很多b可能不是这三个列向量的线性组合。

有时是有界的，当b为这三个列向量的线性组合时方程是有解的。b属于A的列空间。全零，$\begin{bmatrix}1 \\ 2 \\ 3 \\ 4\end{bmatrix}$等等。可以先找出一个x，再得到b。

**Ax=b有解，当且仅当右侧向量b属于A的列空间。**

这三列线性无关吗？如果将这三列进行线性组合，是否每一列都对组合有所贡献。取这三列进行线性组合，最终得到的是三维子空间吗。其中某个向量毫无贡献，只需要两个列向量就能得到一样的空间。去掉第三列后，前两列的线性组合不变，因为第三列是前两列的线性组合，将这两列称为**主列**。也可以去掉第一列，选择后两列为主列。但是可以优先考虑靠前的线性无关向量。第一列可以看作是一个方向上的直线，第二列可以看作是另一个方向上的直线，而第三列在前两列组成的平面上，没有任何贡献，**线性相关**。所以，该矩阵A的列空间可以描述为，R^4中的二维子空间。

### 零空间

仍然是

$$
    A =
    \begin{bmatrix}
        1 & 1 & 2 \\
        2 & 1 & 3 \\
        3 & 1 & 4 \\
        4 & 1 & 5
    \end{bmatrix}
$$

A的零空间，记作N(A)，不包含右侧向量b，而是包含**Ax=0**中的解x，b=0。向量x包含三个分量，因此零空间是R^3的子空间，而列空间是R^4子空间。**对于m*n的矩阵，列空间是R^m的子空间，零空间是R^n的子空间**。列的个数等于未知数的个数，有多少个x乘以这些列。

求零空间和列空间的方法为消元法。

$$
    A =
    \begin{bmatrix}
        1 & 1 & 2 \\
        2 & 1 & 3 \\
        3 & 1 & 4 \\
        4 & 1 & 5
    \end{bmatrix}
$$

$$
    Ax = 0
$$

$$
    \begin{bmatrix}
        1 & 1 & 2 \\
        2 & 1 & 3 \\
        3 & 1 & 4 \\
        4 & 1 & 5
    \end{bmatrix}
    \begin{bmatrix}
        x_1 \\
        x_2 \\
        x_3
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 \\
        0 \\
        0 \\
        0
    \end{bmatrix}
$$

首先零空间必包含零向量，所以$\begin{bmatrix}0\\0\\0\\0\end{bmatrix}$是Ax=0的一个解。

该零空间包含所有形如$\begin{bmatrix}c\\c\\-c\end{bmatrix}$，$\begin{bmatrix}1\\1\\-1\end{bmatrix}$的任意倍数的向量。该零空间为三维空间R^3的中的一条过原点的直线。

零空间为什么是子空间，为什么可以被称作 “空间” ？

检验Ax=0的解构成一个子空间。需要证明一个解v，和另一个解w，Ax=0，Aw=0，则A(v+w)=0。也就是说v，w，(v+w)都在子空间中。

根据矩阵乘法规则，括号可以乘开：

$$
    A(v+w) = Av + Aw = 0
$$

同样也可以证明对于数乘也成立。

理解什么是向量空间的关键，将右侧向量换成$\begin{bmatrix}1\\2\\3\\4\end{bmatrix}$

$$
\begin{bmatrix}
    1 & 1 & 2 \\
    2 & 1 & 3 \\
    3 & 1 & 4 \\
    4 & 1 & 5
\end{bmatrix}
\begin{bmatrix}
    x_1 \\
    x_2 \\
    x_3
\end{bmatrix}
=
\begin{bmatrix}
    1 \\
    2 \\
    3 \\
    4
\end{bmatrix}
$$

四个方程只有三个未知数，如果随便选取右侧向量b，方程很可能无解，但是这个b很特殊，并且已经知道一个解是$\begin{bmatrix}1\\0\\0\end{bmatrix}$，方程是否还有其它解，这些解是否构成向量空间。<br />
现在需要考虑R^3中所有满足Ax=b的解，此时b不再是0，这些解不再构成向量空间。因为**解中不包含零向量**，无法满足最基本的要求。<br />
该方程有很多解，但是不够成向量空间，这些解其实是一个不穿过原点的平面，或者一条不穿过原点的直线。<br />

两种子空间的构造方法：<br />
对于列空间，通过其中的几列取线性组合，通过线性组合构筑向量空间。<br />
对于零空间，一开始不知道其中有那些向量，我们需要自己寻找满足方程组的向量。<br />

## 主变量 特解

如何描述例如列空间、零空间中的向量。从定义转向算法，求解Ax=0，本章主要讨论长方阵。

设
$$
A =
\begin{bmatrix}
    1 & 2 & 2 & 2 \\
    2 & 4 & 6 & 8 \\
    3 & 6 & 8 & 10
\end{bbmatrix}
$$

可以看出，第二列是第一列的两倍，这两列线性相关。可以在消元中发现这一点。对于行来说，第一行加第二行等于第三行，所以第三行与第一行第二行处在同一个平面上，第三行也与前两行线性相关。这一点也能在消元中发现。

本章的算法就是消元，但是消元对象变成了长方阵。哪怕主元位置为0，仍然得继续。

**在消元的过程中，零空间是不会改变的**，这一点非常重要。

**随着消元不会改变的是方程组的解**

$$
\begin{bmatrix}
    1 & 2 & 2 & 2 \\
    2 & 4 & 6 & 8 \\
    3 & 6 & 8 & 10
\end{bbmatrix}
$$

首先将第一列第一个元素下方消为0。

$$
\begin{bmatrix}
    1 & 2 & 2 & 2 \\
    0 & 0 & 2 & 4 \\
    0 & 0 & 2 & 4
\end{bbmatrix}
$$

再查看第二列。第二列的主元位置为0，查看主元下方，希望能够找到部位零的行进行行交换，但是下方全为0。说明第二列是前面列的线性组合，第二列相关与前面各列。此时去找下一个主元，是第二行第三列的元素，继续进行消元，消去该主元下方的元素，得到阶梯形式的矩阵U(echelon form)。

$$
U = 
\begin{bmatrix}
    1 & 2 & 2 & 2 \\
    0 & 0 & 2 & 4 \\
    0 & 0 & 0 & 0
\end{bbmatrix}
$$

本例中只有两个主元。矩阵中最重要的数字就是主元数量，本例中为2，是矩阵的**秩(rank)**。

**秩在算法中的意义就是，表示主元的个数**

下一步是找出主变量和主列。主元所在的两列就是主列，本例中为第一列和第二列。其余列称为自由列。这些自由列表示，可以自由或任意分配数值给这些未知数。例如本例中自由列为第二列和第四列，可以给x_2和x_4任意分配数值，接下来只需解出x_1和x_3。

此时Ux=0表示以下方程组：

$$
\begin{cases}
    x_1 + 2x_2 + 2x_3 + 2x_4 = 0 \\
    2x_3 + 4 x_4 = 0
\end{cases}
$$

x_2和x_4可以任意选择。选择后回代求出x_1和x_3，即可得到方程组的一个解。


完整的算法步骤如下：<br />
1. 消元找到矩阵的主列和自由列，得到主变量和自由变量。
2. 对自由变量分配数值，回代求出一个特解。

以上求出的是矩阵的特解，特定之处在于给自由变量分配的特定值。通过特解能够构造出任意解。

可以取x_2=1, x_4=0，得到的解为$\begin{bmatrix}-2\\1\\0\\0\end{bmatrix}$，取x_2=0, x_4=1，得到的解为$\begin{bmatrix}2\\0\\-2\\1\end{bmatrix}$。得到了这两个解，就得到了这两个解的倍数，也可以得到这两个特解的线性组合。

$$
x = 
c
\begin{bmatrix}
    -2 \\
    1 \\
    0 \\
    0
\end{bmatrix}
+ d
\begin{bmatrix}
    2 \\
    0 \\
    -2 \\
    1
\end{bmatrix}
$$

**零空间所包含的就是特解的线性组合**。每个自由变量对应一个特解

矩阵的秩代表矩阵主变量的个数，也就是主元的个数，对于mxn维秩为r的矩阵，自由变量个数为n-r个。有r个主变量，就表示只有r个方程起作用，剩下的n-r个变量都可以自由选取，令其为0、1这样的值就可以得到其特解。

目前这个矩阵U是阶梯形式，可将其进一步简化为简化行阶梯矩阵(reduced row echelon form)。

矩阵U中0行的出现，是因为第三行为第一行跟第二行的线性组合，消元发现了这一点，所以这行全为0。

可以继续向上消元，让主元上方和下方均为0。

$$
U = 
\begin{bmatrix}
    1 & 2 & 2 & 2 \\
    0 & 0 & 2 & 4 \\
    0 & 0 & 0 & 0
\end{bbmatrix}
$$

$$
\begin{bmatrix}
    1 & 2 & 0 & -2 \\
    0 & 0 & 2 & 4 \\
    0 & 0 & 0 & 0
\end{bbmatrix}
$$

可以用方程除以主元，这样解的空间不会改变，可以使主元位置均为1。

$$
R = 
\begin{bmatrix}
    1 & 2 & 0 & -2 \\
    0 & 0 & 1 & 2 \\
    0 & 0 & 0 & 0
\end{bbmatrix}
$$

Matlab可以用rref(**R**educed **R**ow **E**chelon **F**orm)函数直接实现上述操作。

简化行阶梯矩阵以最简形式包含了所有信息，可以看出主行，主列，主元，零行，自由列等等，这样就可以很快得到特解。还可以看到里面包含一个单位阵位于主列主行交汇处

此时Rx=0为

$$
\begin{cases}
    x_1 + 2x_2 - 2x_4 = 0 \\
    x_3 + 2x_4 = 0
\end{cases}
$$

假设主列在前，R为：

$$
R = 
\begin{bmatrix}
    1 & 0 & 2 & -2 \\
    0 & 1 & 0 & 2 \\
    0 & 0 & 0 & 0
\end{bbmatrix}
$$

这就是典型的rref矩阵，有r个主列在前，n-r个主列在后，

$$
R =
\begin{bmatrix}
    I & F \\
    0 & 0
\end{bmatrix}
$$

此时，可以构造一个“零空间矩阵” N，各列由特解组成，RN=0

如果将单位阵放在自由变量部分，-F放在主变量位置就可以得到N。

$$
N = 
\begin{bmatrix}
    -F \\
    I
\end{bmatrix}
$$

Matlab可以通过命令null求出这个零空间矩阵。

举例：

$$
A = 
\begin{bmatrix}
    1 & 2 & 3 \\
    2 & 4 & 6 \\
    2 & 6 & 8 \\
    2 & 8 & 10
\end{bmatrix}
$$

其实它是前一个例子的A^T。

$$
\begin{bmatrix}
    1 & 2 & 3 \\
    0 & 0 & 0 \\
    0 & 2 & 2 \\
    0 & 4 & 4
\end{bmatrix}
$$

行变换

$$
\begin{bmatrix}
    1 & 2 & 3 \\
    0 & 2 & 2 \\
    0 & 0 & 0 \\
    0 & 4 & 4
\end{bmatrix}
$$

$$
\begin{bmatrix}
    1 & 2 & 3 \\
    0 & 2 & 2 \\
    0 & 0 & 0 \\
    0 & 0 & 0
\end{bmatrix}
$$

$$
R= 
\begin{bmatrix}
    1 & 0 & 1 \\
    0 & 2 & 2 \\
    0 & 0 & 0 \\
    0 & 0 & 0
\end{bmatrix}
$$

秩依然为2。矩阵的特解只有1个

令x_3=1，矩阵的零空间为三维空间中的一条直线：

$$
x = c
\begin{bmatrix}
    -1 \\
    -1 \\
    1
\end{bmatrix}
$$

零基为：

$$
\begin{bmatrix}
    -1 \\
    -1 \\
    1
\end{bmatrix}
$$

矩阵R还可以进一步简化，向上消元，并将主元除为1

$$
\begin{bmatrix}
    1 & 0 & 1 \\
    0 & 1 & 1 \\
    0 & 0 & 0 \\
    0 & 0 & 0
\end{bmatrix}
$$

此时R为：
$$
R= 
\begin{bmatrix}
    I & F \\
    0 & 0
\end{bmatrix}
$$

零空间矩阵为：

$$
N = 
\begin{bmatrix}
    -F \\
    I
\end{bmatrix}
$$

零空间矩阵就是将所有特解作为列的矩阵。